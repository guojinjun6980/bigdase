# bigdase
大规模数据作业
# 研究目的

探索不同的StorageLevel（持久化级别）对Spark作业性能的影响，包括数据处理的运行时间、CPU负载、内存和磁盘I/O的利用情况。

# 研究方法

采用对比实验法，分别对比大小数据集运行的情况，选取相关参数进行对比。

# 实验步骤

## 步骤1：初始化SparkContext

初始化SparkContext，确保环境正常并可以运行Spark作业。

## 步骤2：创建数据集

创建3个不同规模的数据集，模拟不同工作负载。

## 步骤3：定义计算任务

定义计算任务，使用map算子进行简单操作（例如，乘2操作）。这个任务需要执行不同存储级别下的持久化操作。

## 步骤4：应用不同的存储级别

对每个数据集应用不同的存储级别，分别使用MEMORY_ONLY、DISK_ONLY和MEMORY_AND_DISK及其他。

## 步骤5：计时与性能测量

使用Python的time模块来测量不同存储级别下的运行时间，同时收集关于CPU和磁盘的性能数据。

## 步骤6：资源监控

可以使用系统监控工具来监控CPU、内存和磁盘的使用情况。在不同存储级别下，观察CPU的利用率、内存的占用情况以及磁盘的I/O负载。

## 步骤7：清理缓存

每次实验完成后，清理RDD的缓存，防止缓存影响后续实验。

# 研究结果

## 性能表现总结

- **MEMORY_ONLY**：性能最佳，充分利用内存和系统资源，适合内存充足且性能要求高的场景。
- **MEMORY_AND_DISK**：表现接近MEMORY_ONLY，内存不足时将数据溢写到磁盘，是高效且容错的折中方案。
- **DISK_ONLY**：性能最差，依赖磁盘I/O，CPU和系统资源利用率较低，适合内存极度有限的场景。

### 大数据集

- **MEMORY_ONLY** 和 **MEMORY_AND_DISK** 表现优异，CPU使用率高，系统负载均衡，性能稳定。
- **DISK_ONLY** 系统负载最低，但存在性能瓶颈，任务执行效率显著下降。

### 小数据集

- 存储级别差异不大，**MEMORY_ONLY** 和 **MEMORY_AND_DISK** 依然略胜一筹，CPU和内存利用更高。
- **DISK_ONLY** 在小数据集下表现稳定，磁盘I/O开销较小。

## 结论

- **MEMORY_ONLY** 是性能最优的选择。
- **MEMORY_AND_DISK** 适用于内存有限场景。
- **DISK_ONLY** 仅适合对性能要求较低的情况。

# 小组分工

- **孔维鹏**：负责实验设计，测试脚本修改，性能监控模块等（25%）
- **郭晋军**：负责环境搭建，性能监控模块，数据收集，实验结果分析等（25%）
- **宋天民**：负责数据集、测试脚本编写，实验结果分析等（25%）
- **张皓洋**：负责环境搭建，实验结果分析等（25%）
